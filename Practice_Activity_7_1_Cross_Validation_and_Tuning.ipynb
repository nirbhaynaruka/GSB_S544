{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Consider four possible models for predicting house prices:\n",
        "\n",
        "Using only the size and number of rooms.\n",
        "\n",
        "Using size, number of rooms, and building type.\n",
        "\n",
        "Using size and building type, and their interaction.\n",
        "\n",
        "Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
        "\n",
        "Set up a pipeline for each of these four models.\n",
        "\n",
        "Then, get predictions on the test set for each of your pipelines, and compute the root mean squared error. Which model performed best?\n",
        "\n",
        "Note: You should only use the function train_test_split() one time in your code; that is, we should be predicting on the same test set for all three models."
      ],
      "metadata": {
        "id": "irXUQl7zoaqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "clEihTtsoPYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "data = pd.read_csv(\"AmesHousing.csv\")"
      ],
      "metadata": {
        "id": "lVcmuDr4qthc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type']]\n",
        "\n",
        "y = data['SalePrice']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "ct1 = ColumnTransformer(transformers=[\n",
        "    (\"scale\", StandardScaler(), ['Gr Liv Area', 'TotRms AbvGrd'])\n",
        "], remainder='drop')\n",
        "\n",
        "pipeline_1 = Pipeline(steps=[\n",
        "    ('preprocessor', ct1),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "pipeline_1.fit(X_train, y_train)\n",
        "y_pred = pipeline_1.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(sqrt(mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fowv25AJ-IYt",
        "outputId": "d6fa6bf6-2e24-47a0-ba43-eb3c7e1fd14a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55372.453007850665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type']]\n",
        "\n",
        "y = data['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "# Model 1\n",
        "ct1 = ColumnTransformer(transformers=[\n",
        "    (\"scale\", StandardScaler(), ['Gr Liv Area', 'TotRms AbvGrd'])\n",
        "], remainder='drop')\n",
        "\n",
        "pipeline_1 = Pipeline(steps=[\n",
        "    ('preprocessor', ct1),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "# Model 2\n",
        "ct2 = ColumnTransformer(transformers=[\n",
        "    (\"scale\", StandardScaler(), ['Gr Liv Area', 'TotRms AbvGrd']),\n",
        "    (\"dummify\", OneHotEncoder(sparse_output=False), ['Bldg Type'])\n",
        "], remainder='passthrough')\n",
        "pipeline_2 = Pipeline(steps=[\n",
        "    ('preprocessor', ct2),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "# Model 3\n",
        "ct3 = ColumnTransformer(transformers=[\n",
        "    ('cat', OneHotEncoder(), ['Bldg Type'])\n",
        "], remainder='passthrough')\n",
        "pipeline_3 = Pipeline([\n",
        "    ('preprocessor', ct3),\n",
        "    ('interactions', PolynomialFeatures(interaction_only=True, include_bias=False)),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "# Model 4\n",
        "ct4 = ColumnTransformer(transformers=[\n",
        "    (\"size_poly\", PolynomialFeatures(degree=5), ['Gr Liv Area']),\n",
        "    (\"rooms_poly\", PolynomialFeatures(degree=5), ['TotRms AbvGrd']),\n",
        "    (\"dummify\", OneHotEncoder(sparse_output=False), ['Bldg Type'])\n",
        "], remainder='passthrough')\n",
        "pipeline_4 = Pipeline(steps=[\n",
        "    ('preprocessor', ct4),\n",
        "    ('model', LinearRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "B-J-XLfhtiFD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline_3.fit(X_train, y_train)\n",
        "# y_pred = pipeline_3.predict(X_test)\n",
        "# r2 = r2_score(y_test, y_pred)\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "# print(mse)\n",
        "models = [pipeline_1,pipeline_2, pipeline_3, pipeline_4]\n",
        "mse_results = {}\n",
        "\n",
        "for i, model in enumerate(models, 1):\n",
        "    if i == 1:\n",
        "        X_train_mod = X_train[['Gr Liv Area', 'TotRms AbvGrd']]\n",
        "        X_test_mod = X_test[['Gr Liv Area', 'TotRms AbvGrd']]\n",
        "        model.fit(X_train_mod, y_train)\n",
        "        y_pred = model.predict(X_test_mod)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        mse_results[f'Model {i}'] = sqrt(mse)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        mse_results[f'Model {i}'] = sqrt(mse)\n",
        "\n",
        "print(mse_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw8YlsZavUEd",
        "outputId": "8528e4c5-d125-434d-c411-245ff5b958da"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model 1': 55372.453007850665, 'Model 2': 54083.12550273998, 'Model 3': 52903.489062684515, 'Model 4': 53218.50422621488}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3 with mse 52903.489062684515 is the best among the 4 because of lowest mse\n"
      ],
      "metadata": {
        "id": "zUyhARwoz4YW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practice Activity\n",
        "\n",
        "Once again consider four modeling options for house price:\n",
        "\n",
        "Using only the size and number of rooms.\n",
        "\n",
        "Using size, number of rooms, and building type.\n",
        "\n",
        "Using size and building type, and their interaction.\n",
        "\n",
        "Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
        "\n",
        "Use cross_val_score with the pipelines you made earlier to find the cross-validated root mean squared error for each model.\n",
        "\n",
        "Which do you prefer? Does this agree with your conclusion from earlier?"
      ],
      "metadata": {
        "id": "g5kPcTf0ohFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct2 = ColumnTransformer(transformers=[\n",
        "    (\"standardize\", StandardScaler(), ['Gr Liv Area', 'TotRms AbvGrd']),\n",
        "    (\"dummify\", OneHotEncoder(sparse_output=False), ['Bldg Type'])\n",
        "])\n",
        "\n",
        "pipeline_2 = Pipeline(\n",
        "   [ ('preprocessor', ct2),\n",
        "    ('model', LinearRegression())]\n",
        ")\n",
        "scores = cross_val_score(pipeline_2, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "rmse_scores.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA7MlAor1oag",
        "outputId": "05f30d04-e92e-4a24-c09e-b27e80893d6c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54168.081429193844"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_mse_results = {}\n",
        "for i, model in enumerate(models, 1):\n",
        "    if i == 1:\n",
        "        X_mod = X[['Gr Liv Area', 'TotRms AbvGrd']]\n",
        "        scores = cross_val_score(model, X_mod, y, cv=5, scoring='neg_mean_squared_error')\n",
        "        rmse_scores = np.sqrt(-scores)\n",
        "        cross_val_mse_results[f'Model {i}'] = np.mean(rmse_scores)\n",
        "    else:\n",
        "        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "        rmse_scores = np.sqrt(-scores)\n",
        "        cross_val_mse_results[f'Model {i}'] = np.mean(rmse_scores)\n",
        "\n",
        "print(cross_val_mse_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl4dXN-fosz9",
        "outputId": "f2661bf7-12aa-4e81-b1fd-63220e68e61b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model 1': 55806.32634926364, 'Model 2': 54168.081429193844, 'Model 3': 53350.439449155354, 'Model 4': 56303.24517642801}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3 with cross-validated root mean squared error value of 53350.439449155354 is consider to be the best, which is same as of previously, considering rmse of these models."
      ],
      "metadata": {
        "id": "txpALePgBcsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider one hundred modeling options for house price:\n",
        "\n",
        "House size, trying degrees 1 through 10\n",
        "\n",
        "Number of rooms, trying degrees 1 through 10\n",
        "\n",
        "Building Type\n",
        "\n",
        "Hint: The dictionary of possible values that you make to give to GridSearchCV\n",
        "will have two elements instead of one.\n",
        "\n",
        "Q1: Which model performed the best?\n",
        "\n",
        "Q2: What downsides do you see of trying all possible model options? How might you go about choosing a smaller number of tuning values to try?"
      ],
      "metadata": {
        "id": "NsxyXKYZoolu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct_poly = ColumnTransformer(\n",
        "  [\n",
        "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
        "    (\"polynomial\", PolynomialFeatures(), [\"Gr Liv Area\"])\n",
        "  ],\n",
        "  remainder = \"drop\"\n",
        ")\n",
        "\n",
        "lr_pipeline_poly = Pipeline(\n",
        "  [(\"preprocessing\", ct_poly),\n",
        "  (\"linear_regression\", LinearRegression())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "degrees = {'ff': np.arange(1, 10)}\n",
        "\n",
        "gscv = GridSearchCV(lr_pipeline_poly, degrees, cv = 5, scoring='r2')"
      ],
      "metadata": {
        "id": "b7cmy_xaEbWz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct_poly = ColumnTransformer(\n",
        "    [\n",
        "        (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
        "        (\"polynomial_area\", PolynomialFeatures(), [\"Gr Liv Area\"]),\n",
        "        (\"polynomial_room\", PolynomialFeatures(), [\"TotRms AbvGrd\"])\n",
        "\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "lr_pipeline_poly = Pipeline(\n",
        "    [\n",
        "        (\"preprocessing\", ct_poly),\n",
        "        (\"linear_regression\", LinearRegression())\n",
        "    ]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "# Define the degrees to try for polynomial features\n",
        "degrees = {\n",
        "    'preprocessing__polynomial_area__degree': np.arange(1, 11),\n",
        "        'preprocessing__polynomial_room__degree': np.arange(1, 11),\n",
        "    }\n",
        "\n",
        "gscv = GridSearchCV(lr_pipeline_poly, degrees, cv=5, scoring='r2')\n",
        "\n",
        "gscv.fit(X, y)\n",
        "print(gscv.best_params_)\n",
        "print(gscv.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW8XiiD0CLPF",
        "outputId": "762e13e9-90d7-4930-e3f1-c5a81d157184"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'preprocessing__polynomial_area__degree': 3, 'preprocessing__polynomial_room__degree': 1}\n",
            "0.5576406065380459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying all possible models can be time consuming, when dealing with large number of parameters, also it may cause oferfitting because of that.\n",
        "to choose a smaller number of tuning values, we can focus on the data analyisis, or most relevant features, which will reduce the search space, or we can use methods like random search or other."
      ],
      "metadata": {
        "id": "O-5GXjpgLEtO"
      }
    }
  ]
}