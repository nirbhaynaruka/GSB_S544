{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Our dataset consists of clinical data from patients who entered the hospital complaining of chest pain (\"angina\") during exercise.  The information collected includes:\n",
        "\n",
        "* `age` : Age of the patient\n",
        "\n",
        "* `sex` : Sex of the patient\n",
        "\n",
        "* `cp` : Chest Pain type\n",
        "\n",
        "    + Value 0: asymptomatic\n",
        "    + Value 1: typical angina\n",
        "    + Value 2: atypical angina\n",
        "    + Value 3: non-anginal pain\n",
        "   \n",
        "    \n",
        "* `trtbps` : resting blood pressure (in mm Hg)\n",
        "\n",
        "* `chol` : cholesterol in mg/dl fetched via BMI sensor\n",
        "\n",
        "* `restecg` : resting electrocardiographic results\n",
        "\n",
        "    + Value 0: normal\n",
        "    + Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "    + Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "\n",
        "* `thalach` : maximum heart rate achieved during exercise\n",
        "\n",
        "* `output` : the doctor's diagnosis of whether the patient is at risk for a heart attack\n",
        "    + 0 = not at risk of heart attack\n",
        "    + 1 = at risk of heart attack"
      ],
      "metadata": {
        "id": "P_N9XP2-04VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "metadata": {
        "id": "tZmjmGGQ1CaN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ghXbwhv600-S"
      },
      "outputs": [],
      "source": [
        "ha = pd.read_csv(\"https://www.dropbox.com/s/aohbr6yb9ifmc8w/heart_attack.csv?dl=1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1: Natural Multiclass Models\n",
        "\n",
        "Fit a multiclass KNN, Decision Tree, and LDA for the heart disease data; this time predicting the type of chest pain (categories 0 - 3) that a patient experiences.  For the decision tree, plot the fitted tree, and interpret the first couple splits.\n"
      ],
      "metadata": {
        "id": "OCX180v41bhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = ha[['age', 'chol']]\n",
        "y = ha['cp']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5)\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "best_knn = grid_search_knn.best_estimator_\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "param_grid_dt = {\n",
        "    'max_depth': [2, 4, 6, 8],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=5)\n",
        "grid_search_dt.fit(X_train, y_train)\n",
        "best_dt = grid_search_dt.best_estimator_\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print(\"Best KNN Model:\", grid_search_knn.best_params_, \"with accuracy:\", best_knn.score(X_test, y_test))\n",
        "print(\"Best Decision Tree Model:\", grid_search_dt.best_params_, \"with accuracy:\", best_dt.score(X_test, y_test))\n",
        "print(\"LDA Model accuracy:\", lda.score(X_test, y_test))\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# plot_tree(best_dt, filled=True, feature_names=['age', 'chol'], class_names=['Type 0', 'Type 1', 'Type 2', 'Type 3'])\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "WJsMBCZh1glq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b60418a-1449-467f-bdcf-72bff95f3861"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN Model: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'} with accuracy: 0.4057971014492754\n",
            "Best Decision Tree Model: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 4, 'min_samples_split': 2} with accuracy: 0.391304347826087\n",
            "LDA Model accuracy: 0.4782608695652174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2:  OvR\n",
        "\n",
        "Create a new column in the `ha` dataset called `cp_is_3`, which is equal to `1` if the `cp` variable is equal to `3` and `0` otherwise.\n",
        "\n",
        "Then, fit a Logistic Regression to predict this new target, and report the **F1 Score**.\n",
        "\n",
        "Repeat for the other three `cp` categories.  Which category was the OvR approach best at distinguishing?"
      ],
      "metadata": {
        "id": "gYqpOtbO1EAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for cp_val in range(4):\n",
        "    ha[f'cp_is_{cp_val}'] = (ha['cp'] == cp_val).astype(int)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "f1_scores = {}\n",
        "\n",
        "for cp_val in range(4):\n",
        "    y_train, y_test = train_test_split(ha[f'cp_is_{cp_val}'], test_size=0.25, random_state=42)\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    f1_scores[f'cp_is_{cp_val}'] = f1_score(y_test, y_pred)\n",
        "\n",
        "f1_scores\n"
      ],
      "metadata": {
        "id": "90PfjsjW1T2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e3d816-e86e-4aa0-88c6-48d565ecf451"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp_is_0': 0.3272727272727273, 'cp_is_1': 0.0, 'cp_is_2': 0.0, 'cp_is_3': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3: OvO\n",
        "\n",
        "Reduce your dataset to only the `0` and `1` types of chest pain.\n",
        "\n",
        "Then, fit a Logistic Regression to predict between the two groups, and report the **ROC-AUC**.  \n",
        "\n",
        "Repeat comparing category `0` to `2` and `3`.  Which pair was the OvO approach best at distinguishing?"
      ],
      "metadata": {
        "id": "lXO3jbTU1ULR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_and_evaluate_ovo(cp1, cp2):\n",
        "    ha_ovo = ha[ha['cp'].isin([cp1, cp2])]\n",
        "\n",
        "    X_ovo = ha_ovo[['age', 'chol']]\n",
        "    y_ovo = ha_ovo['cp']\n",
        "\n",
        "    X_train_ovo, X_test_ovo, y_train_ovo, y_test_ovo = train_test_split(X_ovo, y_ovo, test_size=0.25, random_state=42)\n",
        "\n",
        "    log_reg_ovo = LogisticRegression()\n",
        "    log_reg_ovo.fit(X_train_ovo, y_train_ovo)\n",
        "    y_pred_proba_ovo = log_reg_ovo.predict_proba(X_test_ovo)[:, 1]\n",
        "\n",
        "    return roc_auc_score(y_test_ovo, y_pred_proba_ovo)\n",
        "\n",
        "roc_auc_scores = {\n",
        "    '0_vs_1': fit_and_evaluate_ovo(0, 1),\n",
        "    '0_vs_2': fit_and_evaluate_ovo(0, 2),\n",
        "    '0_vs_3': fit_and_evaluate_ovo(0, 3)\n",
        "}\n",
        "\n",
        "roc_auc_scores\n"
      ],
      "metadata": {
        "id": "THrjnRoV1siy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211e832b-3b8e-418f-c41b-3c45cec80abb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0_vs_1': 0.5591133004926109,\n",
              " '0_vs_2': 0.7333333333333334,\n",
              " '0_vs_3': 0.5396825396825397}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}